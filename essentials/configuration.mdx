---
title: 'Configuration'
description: 'How to Configure the Gateway'
---

Below details how to configure Glide. For more information on router types see [the router page](/essentials/routers).

## Configuration Structure

Glide's configuration is a declarative [YAML file](https://yaml.org/) with the following high level sections:

- `routers` - defines Glide's routers per model modality (e.g. `routers.language`, `routers.speech`, etc)
- `api` - defines Glide's server configuration for specific protocol. Read more about [this below](#api-configuration)
- `telemetry` - defines configuration for Glide's observability. Read more about [this below](#telemetry).

## Basic Configuration

At its simplest the gateway can be configured with a single router and two models.

This example shows a failover router leveraging OpenAI and Azure OpenAI. For OpenAI, Cohere, and OctoML, only an API key needs to be provided.
All other parameters, including the model, are provided by default. For Azure OpenAI, a model and base_url must be specified.

- `language` - This is the language API endpoint which support a `/chat` endpoints from model providers
- `id` - A unique id for your router
- `strategy` - The type of router can be round-robin, weighted-round-robin, least-latency, priority
- `models/id` - A unique ID for the model configuration

```yaml
routers:
  language:
    - id: my-chat-router
      strategy: priority
      models:
        - id: primary
          openai:
            api_key: "XXXXXXXXX"
        - id: secondary
          azureopenai:
            api_key: "XXXXXX"
            model: "glide-GPT-35" # the Azure OpenAI deployment name
            base_url: "https://mydeployment.openai.azure.com/" # the name of your Azure OpenAI Resource
```

## Advanced Configuration

Additionally, parameters can be specified in the configuration as well. Refer to the `Providers` page for more information on parameters.

```yaml
telemetry:
  logging:
    level: debug  # debug, info, warn, error, fatal
    encoding: console

api:
  http:
    host: 0.0.0.0
    port: 7685
    max_body_size: "2Mi"

routers:
  language:
    - id: openai-pool
      strategy: priority # round-robin, weighted-round-robin, priority, least-latency, priority, etc.
      models:
        - id: primary
          openai: # cohere, azureopenai, gemini, other providers we support
            model: gpt-3.5-turbo
            api_key: ${env:OPENAI_API_KEY}
            default_params:
              temperature: 0.1

        - id: secondary
          cohere:
            model: command-light
            api_key: ${env:COHERE_API_KEY}
            default_params: # set the default request params
              temperature: 0.1

    - id: latency-critical-pool
      strategy: least_latency
      models:
        - id: primary
          timeout_ms: 200
          openai:
            model: gpt-3.5-turbo
            api_key: ${env:OPENAI_API_KEY}

        - id: secondary
          timeout_ms: 200
          cohere:
            api_key: ${env:COHERE_API_KEY}

    - id: cohere-openai-ab-test
      strategy: round_robin
      models:
        - id: openai
          openai:
            api_key: ${env:OPENAI_API_KEY}
        - id: cohere
          cohere:
            api_key: ${env:COHERE_API_KEY}

    - id: weight-test
      strategy: weighted_round_robin
      models:
        - id: openai
          weight: 30
          openai:
            api_key: ${env:OPENAI_API_KEY}
        - id: cohere
          weight: 70
          octoml:
            api_key: ${env:OCTOML_API_KEY}
```

## API Configuration

HTTP is the only supported protocol for Glide's API right now.
The following configurations are exposed for you to tweak:

- `api.http.host` (default: localhost) - defines address to which Glide binds its server. Usually, it's `localhost` or `0.0.0.0`
- `api.http.read_timeout` (default: 3m) - the timeout of data reading from clients
- `api.http.write_timeout` (default: 3m) - the timeout of data writing to clients
- `api.http.idle_timeout` (default: 1m) - the free timeout of the request link for persistent keep-alive connections
- `api.http.max_request_body_size` (default: 4Mb) - max body size of a request

A sample of the configuration:

```yaml
api:
  http:
    host: 0.0.0.0 # default: localhost
    port: 9099 # default 9099
    read_timeout: 3s
    write_timeout: 3s
    idle_timeout: 1s
    max_request_body_size: 2Mi

# everything else
# ...
```

## Telemetry

Telemetry configs defines logging, metrics (coming soon), and traces (coming soon) generated by Glide.
Here are available parameters:

- `telemetry.logging.level` (default: info) - minimal log level to output. Possible values: `debug`, `info`, `warning`, `error`
- `telemetry.logging.encoding` (default: json) - logging encoding. The `json` outputs structured logs useful for production setup while `console` is much more readable, so it fits development setups.
- `telemetry.logging.disable_caller` - controls adding information about place in Glide's codebase where the log was generated
- `telemetry.logging.disable_stacktrace` - controls adding information about full stacktrace to the code that generated logs
- `telemetry.logging.output_paths` (default: [] (an empty array)) - allows to save logging streams to the specified files
- `telemetry.logging.output_paths` (default: {} (an empty map)) - key-value pairs to label each Glide's log record.

A sample of the configuration:

```yaml
telemetry:
  logging:
    level: info # available values: debug, info, warning, error
    encoding: json # available values: console, json
    disable_caller: false
    disable_stacktrace: false
    output_paths: []
    initial_fields: {}

# everything else
# ...
```
